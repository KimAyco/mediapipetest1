<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover"/>
    <title>Sender (Mobile Landscape)</title>
    <link href="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.css" rel="stylesheet">
    <script src="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.js"></script>
    <style>
        :root { --bg: #f8f9fa; --warning-bg: #ffe2e2; --warning-fg: #7a0000; }
        body { font-family: Roboto, sans-serif; margin: 0; background: var(--bg); color: #333; }
        h1 { color: #007f8b; text-align: center; font-size: 1.25rem; margin: 12px 0; }
        .container { display: flex; flex-direction: column; align-items: center; padding: 8px; gap: 10px; }
        .videoView { position: relative; width: 100vw; max-width: 100vh; /* keep landscape fit */ height: 56.25vw; /* 16:9 */ max-height: 56.25vh; background: #000; }
        @media (orientation: landscape) { .videoView { width: 100vh; height: 56.25vh; } }
        video, canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; }
        canvas { pointer-events: none; }
        .controls { width: min(720px, 92vw); display: grid; grid-template-columns: 1fr 1fr; gap: 10px; margin: 6px auto; }
        .server { width: min(720px, 92vw); margin: 6px auto; }
        #recordingProgress { width: min(720px, 92vw); height: 12px; display: none; }
        #orientationOverlay { display: none; position: fixed; inset: 0; background: var(--warning-bg); color: var(--warning-fg); z-index: 1000; display: flex; align-items: center; justify-content: center; text-align: center; padding: 20px; font-weight: 700; font-size: 1.1rem; }
        #distanceStatus { text-align: center; font-weight: bold; }
    </style>
</head>
<body>
    <div id="orientationOverlay">Please rotate your device to landscape to start.</div>
    <h1>Sender (Mobile Landscape)</h1>
    <div class="container">
        <div class="videoView">
            <video id="webcam" autoplay playsinline></video>
            <canvas id="output_canvas"></canvas>
        </div>

        <progress id="recordingProgress" value="0" max="100"></progress>
        <div id="distanceStatus"></div>

        <div class="controls">
            <button id="startButton" class="mdc-button mdc-button--raised"><span class="mdc-button__label">Start Detection</span></button>
            <button id="recordButton" class="mdc-button mdc-button--outlined"><span class="mdc-button__label">Record</span></button>
        </div>

        <div class="server">
            <input id="serverUrl" type="text" placeholder="https://your-render-service.onrender.com/predict" style="width:100%; padding:10px;" />
            <div id="predictionResult" style="margin-top:10px; font-weight:bold;"></div>
        </div>
    </div>

    <script type="module">
        import {
            FilesetResolver,
            DrawingUtils,
            PoseLandmarker,
            HandLandmarker
        } from "https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0";

        const video = document.getElementById("webcam");
        const canvas = document.getElementById("output_canvas");
        const ctx = canvas.getContext("2d");
        const drawingUtils = new DrawingUtils(ctx);
        const distanceStatus = document.getElementById("distanceStatus");
        const startButton = document.getElementById("startButton");
        const recordButton = document.getElementById("recordButton");
        const recordingProgress = document.getElementById("recordingProgress");
        const serverUrlInput = document.getElementById("serverUrl");
        const predictionResult = document.getElementById("predictionResult");
        const orientationOverlay = document.getElementById("orientationOverlay");

        let poseLandmarker, handLandmarker;
        let webcamRunning = false;
        let recording = false;
        let recordedFrames = [];
        const selectedPoseIndices = [0, 1, 4, 9, 10, 11, 12, 13, 14, 15, 16];
        const handSelectedIndices = Array.from({ length: 21 }, (_, i) => i);
        const fingertipIndices = [4, 8, 12, 16, 20];
        const fingertipColors = ["#FF5252", "#4CAF50", "#2196F3", "#FF9800", "#9C27B0"]; // thumb..pinky
        const wristColor = "#9E9E9E";

        const SERVER_URL_DEFAULT = "https://flask-tester-cx5v.onrender.com/predict";
        serverUrlInput.value = SERVER_URL_DEFAULT;
        const getServerUrl = () => (serverUrlInput.value || SERVER_URL_DEFAULT).trim();

        const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
        function landscapeOK() { return !isMobile || window.innerWidth > window.innerHeight; }
        function updateOrientationGuard() {
            const ok = landscapeOK();
            orientationOverlay.style.display = ok ? "none" : "flex";
            startButton.disabled = !ok;
            recordButton.disabled = !ok || !webcamRunning || recording;
            if (!ok && webcamRunning) stopWebcam();
        }
        window.addEventListener("resize", updateOrientationGuard);
        window.addEventListener("orientationchange", updateOrientationGuard);

        window.addEventListener("DOMContentLoaded", async () => {
            await initMediaPipe();
            updateOrientationGuard();
        });

        startButton.addEventListener("click", async () => {
            if (!landscapeOK()) return;
            if (webcamRunning) return;
            webcamRunning = true;
            await enableWebcam();
        });

        recordButton.addEventListener("click", async () => {
            if (!webcamRunning || recording) return;
            recording = true;
            recordedFrames = [];

            let framesCaptured = 0;
            const totalFrames = 9;
            const interval = 50;

            recordingProgress.style.display = "block";
            recordingProgress.value = 0;
            recordingProgress.max = totalFrames;

            const intervalId = setInterval(async () => {
                if (!landscapeOK()) { clearInterval(intervalId); recording = false; recordingProgress.style.display = "none"; return; }
                const nowInMs = performance.now();
                const poseResult = await poseLandmarker.detectForVideo(video, nowInMs);
                const handResult = await handLandmarker.detectForVideo(video, nowInMs);
                const row = [];

                // Pose landmarks (selected indices -> 22 columns)
                if (poseResult.landmarks && poseResult.landmarks[0]) {
                    selectedPoseIndices.forEach(i => {
                        const l = poseResult.landmarks[0][i];
                        if (l) { row.push(Number(l.x.toFixed(5)), Number(l.y.toFixed(5))); }
                        else { row.push(0, 0); }
                    });
                } else {
                    row.push(...Array(selectedPoseIndices.length * 2).fill(0));
                }

                // Hands (ALL 21 landmarks per hand x,y -> 84)
                for (let h = 0; h < 2; h++) {
                    if (handResult.landmarks && handResult.landmarks[h]) {
                        handSelectedIndices.forEach(i => {
                            const l = handResult.landmarks[h][i];
                            if (l) { row.push(Number(l.x.toFixed(5)), Number(l.y.toFixed(5))); }
                            else { row.push(0, 0); }
                        });
                    } else {
                        row.push(...Array(handSelectedIndices.length * 2).fill(0));
                    }
                }

                recordedFrames.push(row);
                framesCaptured++;
                recordingProgress.value = framesCaptured;

                if (framesCaptured >= totalFrames) {
                    clearInterval(intervalId);
                    recording = false;
                    recordingProgress.style.display = "none";
                    sendJSONToServer(recordedFrames); // 9x106
                }
            }, interval);
        });

        function stopWebcam() {
            const stream = video.srcObject;
            if (stream) stream.getTracks().forEach(track => track.stop());
            video.srcObject = null;
            webcamRunning = false;
        }

        async function initMediaPipe() {
            const vision = await FilesetResolver.forVisionTasks(
                "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
            );
            poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
                baseOptions: { modelAssetPath: "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task", delegate: "CPU" },
                runningMode: "VIDEO",
                numPoses: 1
            });
            handLandmarker = await HandLandmarker.createFromOptions(vision, {
                baseOptions: { modelAssetPath: "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task", delegate: "GPU" },
                runningMode: "VIDEO",
                numHands: 2
            });
        }

        async function enableWebcam() {
            const constraints = { video: { facingMode: "user", width: { ideal: 1280 }, height: { ideal: 720 }, aspectRatio: 16/9 } };
            const stream = await navigator.mediaDevices.getUserMedia(constraints);
            video.srcObject = stream;
            video.addEventListener("loadeddata", () => {
                fitCanvasToVideo();
                predictWebcam();
            }, { once: true });
        }

        function fitCanvasToVideo() {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
        }

        function detectDistance(poseLandmarks, vw) {
            if (!poseLandmarks || poseLandmarks.length === 0) return "No pose detected";
            const left = poseLandmarks.find(lm => lm.index === 11);
            const right = poseLandmarks.find(lm => lm.index === 12);
            if (!left || !right) return "Shoulders not detected";
            const shoulderWidthPixels = Math.abs(right.x * vw - left.x * vw);
            const shoulderWidthRelative = shoulderWidthPixels / vw;
            const targetWidthRelative = 0.45;
            const tolerance = 0.05;
            if (shoulderWidthRelative > targetWidthRelative + tolerance) return "Too close";
            if (shoulderWidthRelative < targetWidthRelative - tolerance) return "Too far";
            return "Perfect distance";
        }

        async function predictWebcam() {
            const nowInMs = performance.now();
            const poseResult = await poseLandmarker.detectForVideo(video, nowInMs);
            const handResult = await handLandmarker.detectForVideo(video, nowInMs);

            ctx.clearRect(0, 0, canvas.width, canvas.height);

            if (poseResult.landmarks && poseResult.landmarks[0]) {
                const allPose = poseResult.landmarks[0].map((landmark, index) => ({ ...landmark, index }));
                const filtered = selectedPoseIndices.map(i => allPose.find(lm => lm.index === i)).filter(Boolean);
                drawingUtils.drawLandmarks(filtered, { color: "#00FF00", lineWidth: 2 });
                filtered.forEach((lm) => {
                    const x = lm.x * canvas.width; const y = lm.y * canvas.height;
                    ctx.fillStyle = "#FFFFFF"; ctx.font = "12px Arial"; ctx.fillText(`P${lm.index}`, x + 5, y - 5);
                });
                const distText = detectDistance(allPose, video.videoWidth);
                distanceStatus.textContent = distText;
                distanceStatus.style.color = distText === "Perfect distance" ? "green" : (distText === "Too close" ? "red" : "orange");
            } else {
                distanceStatus.textContent = "No pose detected";
                distanceStatus.style.color = "#2196f3";
            }

            if (handResult.landmarks) {
                for (const hand of handResult.landmarks) {
                    const wrist = hand[0];
                    if (wrist) { const x = wrist.x * canvas.width, y = wrist.y * canvas.height; ctx.beginPath(); ctx.arc(x, y, 4, 0, 2*Math.PI); ctx.fillStyle = wristColor; ctx.fill(); }
                    fingertipIndices.forEach((idx, tipIdx) => {
                        const lm = hand[idx]; if (!lm) return; const x = lm.x * canvas.width, y = lm.y * canvas.height;
                        ctx.beginPath(); ctx.arc(x, y, 4, 0, 2*Math.PI); ctx.fillStyle = fingertipColors[tipIdx % fingertipColors.length]; ctx.fill();
                    });
                }
            }

            if (webcamRunning) window.requestAnimationFrame(predictWebcam);
        }

        async function sendJSONToServer(allFramesData) {
            const payload = { data: allFramesData };
            try {
                const response = await fetch(getServerUrl(), { method: "POST", headers: { "Content-Type": "application/json" }, body: JSON.stringify(payload) });
                const contentType = response.headers.get("Content-Type") || "";
                const text = await response.text();
                if (contentType.includes("application/json")) {
                    const parsed = JSON.parse(text);
                    const label = parsed.prediction ?? "Unknown";
                    const conf = parsed.confidence != null ? ` (conf: ${parsed.confidence})` : "";
                    predictionResult.textContent = `Prediction: ${label}${conf}`;
                } else {
                    predictionResult.textContent = `Server returned non-JSON (status ${response.status}).`;
                }
            } catch (err) {
                predictionResult.textContent = `Server error: ${err.message}`;
            }
        }
    </script>
</body>
</html>


