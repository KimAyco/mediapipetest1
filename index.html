<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"/>
    <title>Sender (Mobile/Desktop Landscape) - mobile_v</title>
    <link href="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.css" rel="stylesheet">
    <script src="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.js"></script>
    <style>
        :root { --ok:#2e7d32; --warn:#b71c1c; --bg:#f8f9fa; }
        body { font-family: Roboto, sans-serif; margin: 0; padding: 16px; color: #333; background: var(--bg); }
        h1 { color: #007f8b; margin: 0 0 12px; text-align: center; }
        .videoView { position: relative; width: 100%; max-width: 960px; margin: 12px auto; aspect-ratio: 16 / 9; background:#000; }
        video, canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }
        canvas { pointer-events: none; }
        #controls { max-width: 960px; margin: 8px auto; display: grid; grid-template-columns: repeat(3, minmax(0,1fr)); gap: 8px; align-items: center; }
        #serverBox { max-width: 960px; margin: 8px auto; }
        #recordingProgress { width: 100%; height: 16px; -webkit-appearance: none; appearance: none; display: none; }
        #recordingProgress::-webkit-progress-bar { background-color: #eee; border-radius: 8px; }
        #recordingProgress::-webkit-progress-value { background-color: #007f8b; border-radius: 8px; }
        #recordingProgress::-moz-progress-bar { background-color: #007f8b; border-radius: 8px; }
        #orientationOverlay { position: fixed; inset: 0; background: rgba(183,28,28,0.9); color:#fff; display:none; align-items:center; justify-content:center; text-align:center; padding: 24px; z-index: 9999; }
        #orientationOverlay .box { max-width: 520px; }
        #distanceStatus { text-align:center; font-weight: 700; margin: 8px auto; }
        .inline { display: inline-flex; gap: 6px; align-items: center; }
        @media (max-width: 900px) { #controls { grid-template-columns: repeat(2, minmax(0,1fr)); } }
        /* Make camera window smaller on mobile */
        @media (max-width: 600px) {
            .videoView { width: 85vw; max-width: 85vw; }
        }
    </style>
</head>
<body>
    <div id="orientationOverlay">
        <div class="box">
            <h2 style="margin:0 0 8px;">Please rotate your device</h2>
            <p>This page works only in landscape on mobile. Rotate to continue.</p>
        </div>
    </div>

    <h1>Pose and Hand Sender (Landscape) - mobile_v</h1>

    <div class="videoView">
        <video id="webcam" autoplay playsinline muted></video>
        <canvas id="output_canvas"></canvas>
    </div>

    <div id="controls">
        <button id="startButton" class="mdc-button mdc-button--raised"><span class="mdc-button__label">Start</span></button>
        <button id="recordButton" class="mdc-button mdc-button--outlined" disabled><span class="mdc-button__label">Record</span></button>
        <button id="switchCam" class="mdc-button mdc-button--outlined"><span class="mdc-button__label">Use Front Camera</span></button>

        <div class="inline">
            <label class="inline"><input id="poseToggle" type="checkbox" checked /> Show Body Pose</label>
        </div>
        <div class="inline">
            <label>Total frames:</label>
            <input id="totalFrames" type="number" min="1" step="1" value="9" style="width:70px;"/>
        </div>
        <div class="inline">
            <label>Frame gap (ms):</label>
            <input id="frameGap" type="number" min="10" step="10" value="50" style="width:80px;"/>
        </div>
    </div>

    <progress id="recordingProgress" value="0" max="100"></progress>
    <div id="distanceStatus"></div>

    <div id="serverBox">
        <input id="serverUrl" type="text" placeholder="https://your-render-service.onrender.com/predict" style="width:100%; padding:10px;" />
        <div id="predictionResult" style="margin-top:10px; font-weight:bold;"></div>
    </div>

    <script type="module">
        import {
            FilesetResolver,
            DrawingUtils,
            PoseLandmarker,
            HandLandmarker
        } from "https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0";

        const video = document.getElementById("webcam");
        const canvas = document.getElementById("output_canvas");
        const ctx = canvas.getContext("2d");
        const drawingUtils = new DrawingUtils(ctx);
        const distanceStatus = document.getElementById("distanceStatus");

        const startButton = document.getElementById("startButton");
        const recordButton = document.getElementById("recordButton");
        const switchCamButton = document.getElementById("switchCam");
        const poseToggle = document.getElementById("poseToggle");
        const totalFramesInput = document.getElementById("totalFrames");
        const frameGapInput = document.getElementById("frameGap");
        const recordingProgress = document.getElementById("recordingProgress");
        const orientationOverlay = document.getElementById("orientationOverlay");

        const serverUrlInput = document.getElementById("serverUrl");
        const predictionResult = document.getElementById("predictionResult");
        const SERVER_URL_DEFAULT = "https://flask-tester-cx5v.onrender.com/predict";
        serverUrlInput.value = SERVER_URL_DEFAULT;
        const getServerUrl = () => (serverUrlInput.value || SERVER_URL_DEFAULT).trim();

        let poseLandmarker, handLandmarker;
        let webcamRunning = false;
        let recording = false;
        let recordedFrames = [];
        let useFront = false;

        const selectedPoseIndices = [0, 1, 4, 9, 10, 11, 12, 13, 14, 15, 16];
        const fingertipIndices = [4, 8, 12, 16, 20];
        const handSelectedIndices = Array.from({ length: 21 }, (_, i) => i);
        const fingertipColors = ["#FF5252", "#4CAF50", "#2196F3", "#FF9800", "#9C27B0"]; // thumb..pinky
        const wristColor = "#9E9E9E";
        let showBodyPose = true;

        poseToggle.addEventListener("change", () => { showBodyPose = poseToggle.checked; });
        switchCamButton.addEventListener("click", async () => {
            useFront = !useFront;
            switchCamButton.textContent = useFront ? "Use Rear Camera" : "Use Front Camera";
            if (webcamRunning) await enableWebcam(true);
        });

        function isLandscape() {
            const mq = window.matchMedia && window.matchMedia("(orientation: landscape)");
            return (mq && mq.matches) || (window.innerWidth > window.innerHeight);
        }

        function updateOrientationUI() {
            const ok = isLandscape();
            orientationOverlay.style.display = ok ? "none" : "flex";
            // Allow Start to request permission even in portrait; we still block recording when not landscape
            startButton.disabled = false;
            recordButton.disabled = !ok || !webcamRunning;
        }

        window.addEventListener("orientationchange", updateOrientationUI);
        window.addEventListener("resize", updateOrientationUI);

        window.addEventListener("DOMContentLoaded", async () => {
            updateOrientationUI();
            await initMediaPipe();
        });

        startButton.addEventListener("click", async () => {
            if (webcamRunning) return;
            await enableWebcam(false);
        });

        recordButton.addEventListener("click", async () => {
            if (recording) return;
            recording = true;
            recordedFrames = [];

            const totalFrames = Math.max(1, parseInt(totalFramesInput.value || "9", 10));
            const interval = Math.max(10, parseInt(frameGapInput.value || "50", 10));

            recordingProgress.style.display = "block";
            recordingProgress.value = 0;
            recordingProgress.max = totalFrames;

            let framesCaptured = 0;
            const intervalId = setInterval(async () => {
                if (!isLandscape()) return; // don't capture in portrait

                const nowInMs = performance.now();
                const poseResult = showBodyPose ? await poseLandmarker.detectForVideo(video, nowInMs) : { landmarks: null };
                const handResult = await handLandmarker.detectForVideo(video, nowInMs);
                const row = [];

                // Pose: 22 columns
                if (showBodyPose && poseResult.landmarks && poseResult.landmarks[0]) {
                    selectedPoseIndices.forEach(i => {
                        const l = poseResult.landmarks[0][i];
                        row.push(l ? Number(l.x.toFixed(5)) : 0, l ? Number(l.y.toFixed(5)) : 0);
                    });
                } else {
                    row.push(...Array(selectedPoseIndices.length * 2).fill(0));
                }

                // Hands: 84 columns (2 hands × 21 × x,y)
                for (let h = 0; h < 2; h++) {
                    if (handResult.landmarks && handResult.landmarks[h]) {
                        handSelectedIndices.forEach(i => {
                            const l = handResult.landmarks[h][i];
                            row.push(l ? Number(l.x.toFixed(5)) : 0, l ? Number(l.y.toFixed(5)) : 0);
                        });
                    } else {
                        row.push(...Array(handSelectedIndices.length * 2).fill(0));
                    }
                }

                recordedFrames.push(row);
                framesCaptured++;
                recordingProgress.value = framesCaptured;

                if (framesCaptured >= totalFrames) {
                    clearInterval(intervalId);
                    recording = false;
                    recordingProgress.style.display = "none";
                    sendJSONToServer(recordedFrames);
                }
            }, interval);
        });

        async function sendJSONToServer(allFramesData) {
            const payload = { data: allFramesData };
            predictionResult.textContent = "";
            try {
                const response = await fetch(getServerUrl(), {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify(payload)
                });
                const contentType = response.headers.get("Content-Type") || "";
                const text = await response.text();
                if (contentType.includes("application/json")) {
                    const parsed = JSON.parse(text);
                    const label = parsed.prediction ?? "Unknown";
                    const conf = parsed.confidence != null ? ` (conf: ${parsed.confidence})` : "";
                    predictionResult.textContent = `Prediction: ${label}${conf}`;
                } else {
                    predictionResult.textContent = `Server returned non-JSON (status ${response.status}).`;
                }
            } catch (e) {
                predictionResult.textContent = `Server error: ${e.message}`;
            }
        }

        async function initMediaPipe() {
            const vision = await FilesetResolver.forVisionTasks(
                "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
            );
            poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task",
                    delegate: "CPU"
                },
                runningMode: "VIDEO",
                numPoses: 1
            });
            handLandmarker = await HandLandmarker.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task",
                    delegate: "GPU"
                },
                runningMode: "VIDEO",
                numHands: 2
            });
        }

        async function enableWebcam(restart) {
            try {
                const constraints = {
                    audio: false,
                    video: {
                        facingMode: useFront ? { ideal: "user" } : { ideal: "environment" },
                        width: { ideal: 1280 },
                        height: { ideal: 720 },
                        frameRate: { ideal: 30 }
                    }
                };
                if (restart && video.srcObject) {
                    const streamOld = video.srcObject; streamOld.getTracks().forEach(t => t.stop());
                }
                let stream;
                try {
                    stream = await navigator.mediaDevices.getUserMedia(constraints);
                } catch (e1) {
                    // Fallback: basic request
                    try {
                        stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
                    } catch (e2) {
                        // Fallback: explicit facingMode without ideals
                        const fm = useFront ? "user" : "environment";
                        stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: fm }, audio: false });
                    }
                }
                video.srcObject = stream;
                video.addEventListener("loadeddata", () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    webcamRunning = true;
                    recordButton.disabled = !isLandscape();
                    requestAnimationFrame(predictWebcam);
                }, { once: true });
            } catch (e) {
                console.error("getUserMedia failed:", e);
                const secure = window.isSecureContext;
                const hint = secure ? "Check site camera permission in browser settings (allow camera)." : "This page must be served over HTTPS or localhost for camera access.";
                alert("Camera access failed: " + e.message + "\n\n" + hint);
            }
        }

        function detectDistance(poseLandmarks, vw) {
            if (!poseLandmarks || poseLandmarks.length === 0) return "No pose detected";
            const left = poseLandmarks.find(lm => lm.index === 11);
            const right = poseLandmarks.find(lm => lm.index === 12);
            if (!left || !right) return "Shoulders not detected";
            const shoulderWidthRelative = Math.abs(right.x * vw - left.x * vw) / vw;
            const targetWidthRelative = 0.45, tol = 0.05;
            if (shoulderWidthRelative > targetWidthRelative + tol) return "Too close";
            if (shoulderWidthRelative < targetWidthRelative - tol) return "Too far";
            return "Perfect distance";
        }

        async function predictWebcam() {
            if (!webcamRunning) return;
            const nowInMs = performance.now();
            const poseResult = showBodyPose ? await poseLandmarker.detectForVideo(video, nowInMs) : { landmarks: null };
            const handResult = await handLandmarker.detectForVideo(video, nowInMs);

            ctx.clearRect(0, 0, canvas.width, canvas.height);

            if (showBodyPose && poseResult.landmarks && poseResult.landmarks[0]) {
                const allPoseLandmarks = poseResult.landmarks[0].map((landmark, index) => ({ ...landmark, index }));
                const filtered = selectedPoseIndices.map(i => allPoseLandmarks.find(lm => lm.index === i)).filter(Boolean);
                drawingUtils.drawLandmarks(filtered, { color: "#00FF00", lineWidth: 2 });
                const distTxt = detectDistance(allPoseLandmarks, video.videoWidth);
                distanceStatus.textContent = distTxt;
                distanceStatus.style.color = distTxt === "Perfect distance" ? "var(--ok)" : (distTxt === "Too far" ? "#fb8c00" : "var(--warn)");
            } else {
                distanceStatus.textContent = showBodyPose ? "No pose detected" : "";
                distanceStatus.style.color = "#2196f3";
            }

            if (handResult.landmarks) {
                for (const hand of handResult.landmarks) {
                    const wrist = hand[0];
                    if (wrist) { const x = wrist.x * canvas.width, y = wrist.y * canvas.height; ctx.beginPath(); ctx.arc(x, y, 4, 0, 2*Math.PI); ctx.fillStyle = wristColor; ctx.fill(); }
                    fingertipIndices.forEach((idx, tipIdx) => {
                        const lm = hand[idx]; if (!lm) return;
                        const x = lm.x * canvas.width, y = lm.y * canvas.height;
                        ctx.beginPath(); ctx.arc(x, y, 4, 0, 2*Math.PI); ctx.fillStyle = fingertipColors[tipIdx % fingertipColors.length]; ctx.fill();
                    });
                }
            }

            requestAnimationFrame(predictWebcam);
        }
    </script>
</body>
</html>


