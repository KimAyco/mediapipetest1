<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <title>Pose & Hand Detection with Distance</title>
    <link href="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.css" rel="stylesheet">
    <script src="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.js"></script>
    <style>
        body { font-family: Roboto, sans-serif; margin: 2em; color: #333; background-color: #f8f9fa; text-align: center; }
        h1 { color: #007f8b; margin-bottom: 1em; }
        .videoView { position: relative; width: 600px; height: 400px; margin: auto; }
        video, canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }
        canvas { pointer-events: none; }
        button, input[type="file"], #distanceStatus, #recordingProgress { display: block; margin: 20px auto; }
        #loadingContainer { display: flex; justify-content: center; align-items: center; flex-direction: column; margin-bottom: 1em; }
        .mdc-linear-progress { width: 60%; margin: auto; }
        #loadingText { margin-bottom: 1em; font-size: 1.1em; color: #555; }
        #startButton, #recordButton, #csvLoader { display: none; }
        #distanceStatus { font-size: 1.2em; font-weight: bold; color: #2196f3; }
        #recordingProgress { width: 80%; height: 20px; -webkit-appearance: none; appearance: none; display: none; }
        #recordingProgress::-webkit-progress-bar { background-color: #eee; border-radius: 10px; }
        #recordingProgress::-webkit-progress-value { background-color: #007f8b; border-radius: 10px; }
        #recordingProgress::-moz-progress-bar { background-color: #007f8b; border-radius: 10px; }
    </style>
</head>
<body>
    <h1>Pose and Hand Detection with Distance</h1>

    <div id="loadingContainer">
        <div id="loadingText">Loading MediaPipe models, please wait...</div>
        <div role="progressbar" class="mdc-linear-progress mdc-linear-progress--indeterminate" id="loadingBar">
            <div class="mdc-linear-progress__buffer">
                <div class="mdc-linear-progress__buffer-bar"></div>
                <div class="mdc-linear-progress__buffer-dots"></div>
            </div>
            <div class="mdc-linear-progress__bar mdc-linear-progress__primary-bar"><span class="mdc-linear-progress__bar-inner"></span></div>
            <div class="mdc-linear-progress__bar mdc-linear-progress__secondary-bar"><span class="mdc-linear-progress__bar-inner"></span></div>
        </div>
    </div>

    <div class="videoView">
        <video id="webcam" autoplay playsinline></video>
        <canvas id="output_canvas"></canvas>
    </div>

    <progress id="recordingProgress" value="0" max="100"></progress>    
    <div id="distanceStatus"></div>

    <button id="recordButton" class="mdc-button mdc-button--outlined"><span class="mdc-button__label">Record</span></button>
    <button id="startButton" class="mdc-button mdc-button--raised"><span class="mdc-button__label">Start Detection</span></button>
    <input type="file" id="csvLoader" accept=".csv" />
    
    <script type="module">
        import { FilesetResolver, DrawingUtils, PoseLandmarker, HandLandmarker } 
        from "https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0";
    
        const video = document.getElementById("webcam");
        const canvas = document.getElementById("output_canvas");
        const ctx = canvas.getContext("2d");
        const drawingUtils = new DrawingUtils(ctx);
        const distanceStatus = document.getElementById("distanceStatus");
    
        const loadingContainer = document.getElementById("loadingContainer");
        const startButton = document.getElementById("startButton");
        const recordButton = document.getElementById("recordButton");
        const csvLoader = document.getElementById("csvLoader");
        const recordingProgress = document.getElementById("recordingProgress");
    
        let poseLandmarker, handLandmarker;
        let webcamRunning = false;
        let recording = false;
        let recordedFrames = [];
        const selectedPoseIndices = [0, 1, 4, 9, 10, 11, 12, 13, 14, 15, 16]; // 11 pose indices
    
        const SERVER_URL = "https://flask-tester-cx5v.onrender.com/predict"; 
    
        window.addEventListener("DOMContentLoaded", async () => {
            await initMediaPipe();
            loadingContainer.style.display = "none";
            startButton.style.display = "block";
            recordButton.style.display = "block";
            csvLoader.style.display = "block";
        });
    
        startButton.addEventListener("click", async () => {
            if (webcamRunning) return;
            webcamRunning = true;
            await enableWebcam();
        });
    
        // --- Recording (9x24) ---
        recordButton.addEventListener("click", async () => {
            if (recording) return;
            recording = true;
            recordedFrames = [];
    
            let framesCaptured = 0;
            const totalFrames = 9;
            const interval = 50;
    
            recordingProgress.style.display = "block";
            recordingProgress.value = 0;
            recordingProgress.max = totalFrames;
    
            const intervalId = setInterval(async () => {
                const nowInMs = performance.now();
                const poseResult = await poseLandmarker.detectForVideo(video, nowInMs);
                const handResult = await handLandmarker.detectForVideo(video, nowInMs);
                const row = [];
    
                // Pose: 22 features
                if (poseResult.landmarks && poseResult.landmarks[0]) {
                    const currentPoseLandmarks = poseResult.landmarks[0];
                    selectedPoseIndices.forEach(i => {
                        const l = currentPoseLandmarks[i];
                        if (l) row.push(l.x, l.y);
                        else row.push(0, 0);
                    });
                } else {
                    row.push(...Array(selectedPoseIndices.length * 2).fill(0));
                }
    
                // Hand: only wrist (index 0) → 2 features
                if (handResult.landmarks && handResult.landmarks[0]) {
                    const wrist = handResult.landmarks[0][0];
                    if (wrist) row.push(wrist.x, wrist.y);
                    else row.push(0, 0);
                } else {
                    row.push(0, 0);
                }
    
                recordedFrames.push(row);
                framesCaptured++;
    
                recordingProgress.value = framesCaptured;
    
                if (framesCaptured >= totalFrames) {
                    clearInterval(intervalId);
                    recording = false;
                    recordingProgress.style.display = "none";
                    sendJSONToServer(recordedFrames);
                }
            }, interval);
        });
    
        async function sendJSONToServer(allFramesData) {
            const payload = { data: allFramesData };
            try {
                const response = await fetch(SERVER_URL, {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify(payload)
                });
                const text = await response.text();
                console.log(`✅ Raw Text:\n${text}`);
                alert("Prediction: " + text);
            } catch (err) {
                console.error("❌ Error:", err.message);
                alert("Server error: " + err.message);
            }
        }
    
        async function initMediaPipe() {
            const vision = await FilesetResolver.forVisionTasks(
                "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
            );
            poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
                baseOptions: { modelAssetPath: "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task" },
                runningMode: "VIDEO", numPoses: 1
            });
            handLandmarker = await HandLandmarker.createFromOptions(vision, {
                baseOptions: { modelAssetPath: "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task" },
                runningMode: "VIDEO", numHands: 2
            });
        }
    
        async function enableWebcam() {
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;
            video.addEventListener("loadeddata", () => {
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                predictWebcam();
            });
        }
    
        async function predictWebcam() {
            const nowInMs = performance.now();
            const poseResult = await poseLandmarker.detectForVideo(video, nowInMs);
            const handResult = await handLandmarker.detectForVideo(video, nowInMs);
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            if (poseResult.landmarks && poseResult.landmarks[0]) {
                drawingUtils.drawLandmarks(poseResult.landmarks[0], { color: "#00FF00", lineWidth: 2 });
            }
            if (handResult.landmarks) {
                for (const hand of handResult.landmarks) {
                    drawingUtils.drawLandmarks(hand, { color: "#0000FF", lineWidth: 2 });
                }
            }
            if (webcamRunning) window.requestAnimationFrame(predictWebcam);
        }
    
        // --- CSV Replay (force 24 features) ---
        document.getElementById("csvLoader").addEventListener("change", async (e) => {
            const file = e.target.files[0];
            if (!file) return;
            const text = await file.text();
            const lines = text.trim().split("\n").slice(1);
            const parsedFrames = lines.map(line =>
                line.split(",").map(v => parseFloat(v) || 0).slice(0, 24)
            );
            sendJSONToServer(parsedFrames);
        });
    </script>
</body>
</html>
